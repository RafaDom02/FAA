{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "489ea95a",
   "metadata": {},
   "source": [
    "# Apartado I (Naive-Bayes propio heart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e4f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datos import Datos\n",
    "import EstrategiaParticionado\n",
    "import Clasificador\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "593d81c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOMINAL ATRIBUTOS HEART\n",
      "[False, True, True, False, False, False, True, False, True, False, True, True]\n",
      "DICCIONARIO HEART\n",
      "{'Age': {}, 'Sex': {'F': 0, 'M': 1}, 'ChestPainType': {'ASY': 0, 'ATA': 1, 'NAP': 2, 'TA': 3}, 'RestingBP': {}, 'Cholesterol': {}, 'FastingBS': {}, 'RestingECG': {'LVH': 0, 'Normal': 1, 'ST': 2}, 'MaxHR': {}, 'ExerciseAngina': {'N': 0, 'Y': 1}, 'Oldpeak': {}, 'ST_Slope': {'Down': 0, 'Flat': 1, 'Up': 2}, 'Class': {'0': 0, '1': 1}}\n",
      "MATRIZ DE DATOS HEART\n",
      "    Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
      "0  40.0  1.0            1.0      140.0        289.0        0.0         1.0   \n",
      "1  49.0  0.0            2.0      160.0        180.0        0.0         1.0   \n",
      "2  37.0  1.0            1.0      130.0        283.0        0.0         2.0   \n",
      "3  48.0  0.0            0.0      138.0        214.0        0.0         1.0   \n",
      "4  54.0  1.0            2.0      150.0        195.0        0.0         1.0   \n",
      "\n",
      "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  Class  \n",
      "0  172.0             0.0      0.0       2.0    0.0  \n",
      "1  156.0             0.0      1.0       1.0    1.0  \n",
      "2   98.0             0.0      0.0       2.0    0.0  \n",
      "3  108.0             1.0      1.5       1.0    1.0  \n",
      "4  122.0             0.0      0.0       2.0    0.0  \n"
     ]
    }
   ],
   "source": [
    "dataset_1=Datos('./datasets/heart.csv')\n",
    "print(\"NOMINAL ATRIBUTOS HEART\")\n",
    "print(dataset_1.nominalAtributos)\n",
    "print(\"DICCIONARIO HEART\")\n",
    "print (dataset_1.diccionarios)\n",
    "print(\"MATRIZ DE DATOS HEART\")\n",
    "print(dataset_1.datos.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd6376e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDACIÓN CRUZADA HEART\n",
      "Train-particion 0:  RangeIndex(start=91, stop=918, step=1)\n",
      "Test-particion 0:  RangeIndex(start=0, stop=91, step=1)\n"
     ]
    }
   ],
   "source": [
    "estrategiaVC=EstrategiaParticionado.ValidacionCruzada(10)\n",
    "estrategiaVC.creaParticiones(dataset_1.datos)       # datos se refiere a la matriz numérica calculada en Datos\n",
    "print(\"VALIDACIÓN CRUZADA HEART\")\n",
    "print(\"Train-particion 0: \", estrategiaVC.particiones[0].indicesTrain)       # particiones contiene la lista de particiones\n",
    "print(\"Test-particion 0: \", estrategiaVC.particiones[0].indicesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b83e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDACIÓN SIMPLE HEART\n",
      "Train-particion 0:  Index([  0,   1,   3,   4,   5,   8,   9,  10,  12,  13,\n",
      "       ...\n",
      "       904, 905, 906, 910, 911, 912, 913, 914, 915, 917],\n",
      "      dtype='int64', length=643)\n",
      "Test-particion 0:  Index([660, 389, 673, 763, 274, 197, 676, 908, 525, 550,\n",
      "       ...\n",
      "       427, 881, 754, 293, 822, 824, 429, 199, 528, 825],\n",
      "      dtype='int64', length=275)\n"
     ]
    }
   ],
   "source": [
    "estrategiaVS=EstrategiaParticionado.ValidacionSimple(10, 0.3)\n",
    "estrategiaVS.creaParticiones(dataset_1.datos)       # datos se refiere a la matriz numérica calculada en Datos\n",
    "print(\"VALIDACIÓN SIMPLE HEART\")\n",
    "print(\"Train-particion 0: \", estrategiaVS.particiones[0].indicesTrain)       # particiones contiene la lista de particiones\n",
    "print(\"Test-particion 0: \", estrategiaVS.particiones[0].indicesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd7f530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validación Simple de datos HEART\n",
      "Numero de particiones realizadas: 10\n",
      "Numero de particiones realizadas: 10\n",
      "Indice de errores por partición:\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |       0.173913 |\n",
      "+----------------+----------------+\n",
      "|              2 |       0.173913 |\n",
      "+----------------+----------------+\n",
      "|              3 |       0.157609 |\n",
      "+----------------+----------------+\n",
      "|              4 |       0.152174 |\n",
      "+----------------+----------------+\n",
      "|              5 |       0.130435 |\n",
      "+----------------+----------------+\n",
      "|              6 |       0.146739 |\n",
      "+----------------+----------------+\n",
      "|              7 |       0.146739 |\n",
      "+----------------+----------------+\n",
      "|              8 |       0.13587  |\n",
      "+----------------+----------------+\n",
      "|              9 |       0.141304 |\n",
      "+----------------+----------------+\n",
      "|             10 |       0.13587  |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.014430345703643202, media: 0.14945652173913043\n",
      "##################################################\n",
      "Indice de errores por partición (con corrección La Place):\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |       0.173913 |\n",
      "+----------------+----------------+\n",
      "|              2 |       0.173913 |\n",
      "+----------------+----------------+\n",
      "|              3 |       0.157609 |\n",
      "+----------------+----------------+\n",
      "|              4 |       0.152174 |\n",
      "+----------------+----------------+\n",
      "|              5 |       0.130435 |\n",
      "+----------------+----------------+\n",
      "|              6 |       0.146739 |\n",
      "+----------------+----------------+\n",
      "|              7 |       0.146739 |\n",
      "+----------------+----------------+\n",
      "|              8 |       0.13587  |\n",
      "+----------------+----------------+\n",
      "|              9 |       0.141304 |\n",
      "+----------------+----------------+\n",
      "|             10 |       0.13587  |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.014430345703643202, media: 0.14945652173913043\n"
     ]
    }
   ],
   "source": [
    "print(\"Validación Simple de datos HEART\")\n",
    "estrategia = EstrategiaParticionado.ValidacionSimple(10, 0.2)\n",
    "clasificador = Clasificador.Clasificador()\n",
    "nb1 = Clasificador.ClasificadorNaiveBayes()\n",
    "errores1 = clasificador.validacion(estrategia, dataset_1, nb1, None)\n",
    "nb2 = Clasificador.ClasificadorNaiveBayes(True)\n",
    "errores2 = clasificador.validacion(estrategia, dataset_1, nb2, None)\n",
    "\n",
    "headers = [\"Nº particion\", \"Indice error\"]\n",
    "\n",
    "desviacion_estandar = np.std(errores1)\n",
    "media = sum(errores1) / len(errores1)\n",
    "print(\"Indice de errores por partición:\")\n",
    "table = tabulate(enumerate(errores1, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))\n",
    "print(50*\"#\")\n",
    "\n",
    "desviacion_estandar = np.std(errores2)\n",
    "media = sum(errores2) / len(errores2)\n",
    "print(\"Indice de errores por partición (con corrección La Place):\")\n",
    "table = tabulate(enumerate(errores2, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79296b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validación cruzada de datos HEART\n",
      "Numero de particiones realizadas: 10\n",
      "Numero de particiones realizadas: 10\n",
      "Indice de errores por partición:\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |      0.142857  |\n",
      "+----------------+----------------+\n",
      "|              2 |      0.0989011 |\n",
      "+----------------+----------------+\n",
      "|              3 |      0.10989   |\n",
      "+----------------+----------------+\n",
      "|              4 |      0.0549451 |\n",
      "+----------------+----------------+\n",
      "|              5 |      0.0879121 |\n",
      "+----------------+----------------+\n",
      "|              6 |      0.0989011 |\n",
      "+----------------+----------------+\n",
      "|              7 |      0.175824  |\n",
      "+----------------+----------------+\n",
      "|              8 |      0.230769  |\n",
      "+----------------+----------------+\n",
      "|              9 |      0.175824  |\n",
      "+----------------+----------------+\n",
      "|             10 |      0.241758  |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.0594727873746585, media: 0.14175824175824175\n",
      "##################################################\n",
      "Indice de errores por partición (con corrección La Place):\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |      0.142857  |\n",
      "+----------------+----------------+\n",
      "|              2 |      0.0989011 |\n",
      "+----------------+----------------+\n",
      "|              3 |      0.10989   |\n",
      "+----------------+----------------+\n",
      "|              4 |      0.0549451 |\n",
      "+----------------+----------------+\n",
      "|              5 |      0.0879121 |\n",
      "+----------------+----------------+\n",
      "|              6 |      0.0989011 |\n",
      "+----------------+----------------+\n",
      "|              7 |      0.175824  |\n",
      "+----------------+----------------+\n",
      "|              8 |      0.230769  |\n",
      "+----------------+----------------+\n",
      "|              9 |      0.175824  |\n",
      "+----------------+----------------+\n",
      "|             10 |      0.241758  |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.0594727873746585, media: 0.14175824175824175\n"
     ]
    }
   ],
   "source": [
    "print(\"Validación cruzada de datos HEART\")\n",
    "estrategia = EstrategiaParticionado.ValidacionCruzada(10)\n",
    "clasificador = Clasificador.Clasificador()\n",
    "nb1 = Clasificador.ClasificadorNaiveBayes()\n",
    "errores1 = clasificador.validacion(estrategia, dataset_1, nb1, None)\n",
    "nb2 = Clasificador.ClasificadorNaiveBayes(True)\n",
    "errores2 = clasificador.validacion(estrategia, dataset_1, nb2, None)\n",
    "\n",
    "desviacion_estandar = np.std(errores1)\n",
    "media = sum(errores1) / len(errores1)\n",
    "print(\"Indice de errores por partición:\")\n",
    "table = tabulate(enumerate(errores1, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))\n",
    "print(50*\"#\")\n",
    "\n",
    "desviacion_estandar = np.std(errores2)\n",
    "media = sum(errores2) / len(errores2)\n",
    "print(\"Indice de errores por partición (con corrección La Place):\")\n",
    "table = tabulate(enumerate(errores2, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c7f6c",
   "metadata": {},
   "source": [
    "# Apartado I (Naive-Bayes propio TIC-TAC-TOE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc8341f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOMINAL ATRIBUTOS TIC-TAC-TOE\n",
      "[True, True, True, True, True, True, True, True, True, True]\n",
      "DICCIONARIO TIC-TAC-TOE\n",
      "{'TLeftSq': {'b': 0, 'o': 1, 'x': 2}, 'TMidSq': {'b': 0, 'o': 1, 'x': 2}, 'TRightSq': {'b': 0, 'o': 1, 'x': 2}, 'MLeftSq': {'b': 0, 'o': 1, 'x': 2}, 'MMidSq': {'b': 0, 'o': 1, 'x': 2}, 'MRightSq': {'b': 0, 'o': 1, 'x': 2}, 'BLeftSq': {'b': 0, 'o': 1, 'x': 2}, 'BMidSq': {'b': 0, 'o': 1, 'x': 2}, 'BRightSq': {'b': 0, 'o': 1, 'x': 2}, 'Class': {'negative': 0, 'positive': 1}}\n",
      "MATRIZ DE DATOS TIC-TAC-TOE\n",
      "   TLeftSq  TMidSq  TRightSq  MLeftSq  MMidSq  MRightSq  BLeftSq  BMidSq  \\\n",
      "0      2.0     2.0       2.0      2.0     1.0       1.0      2.0     1.0   \n",
      "1      2.0     2.0       2.0      2.0     1.0       1.0      1.0     2.0   \n",
      "2      2.0     2.0       2.0      2.0     1.0       1.0      1.0     1.0   \n",
      "3      2.0     2.0       2.0      2.0     1.0       1.0      1.0     0.0   \n",
      "4      2.0     2.0       2.0      2.0     1.0       1.0      0.0     1.0   \n",
      "\n",
      "   BRightSq  Class  \n",
      "0       1.0    1.0  \n",
      "1       1.0    1.0  \n",
      "2       2.0    1.0  \n",
      "3       0.0    1.0  \n",
      "4       0.0    1.0  \n"
     ]
    }
   ],
   "source": [
    "dataset_2=Datos('./datasets/tic-tac-toe.csv')\n",
    "print(\"NOMINAL ATRIBUTOS TIC-TAC-TOE\")\n",
    "print(dataset_2.nominalAtributos)\n",
    "print(\"DICCIONARIO TIC-TAC-TOE\")\n",
    "print (dataset_2.diccionarios)\n",
    "print(\"MATRIZ DE DATOS TIC-TAC-TOE\")\n",
    "print(dataset_2.datos.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50bb31cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDACIÓN CRUZADA TIC-TAC-TOE\n",
      "Train-particion 0:  RangeIndex(start=95, stop=958, step=1)\n",
      "Test-particion 0:  RangeIndex(start=0, stop=95, step=1)\n"
     ]
    }
   ],
   "source": [
    "estrategiaVC=EstrategiaParticionado.ValidacionCruzada(10)\n",
    "estrategiaVC.creaParticiones(dataset_2.datos)       # datos se refiere a la matriz numérica calculada en Datos\n",
    "print(\"VALIDACIÓN CRUZADA TIC-TAC-TOE\")\n",
    "print(\"Train-particion 0: \", estrategiaVC.particiones[0].indicesTrain)       # particiones contiene la lista de particiones\n",
    "print(\"Test-particion 0: \", estrategiaVC.particiones[0].indicesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6ea8ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDACIÓN SIMPLE TIC-TAC-TOE\n",
      "Train-particion 0:  Index([  1,   4,   5,   9,  11,  14,  15,  16,  17,  18,\n",
      "       ...\n",
      "       906, 907, 908, 909, 910, 911, 912, 913, 916, 917],\n",
      "      dtype='int64', length=643)\n",
      "Test-particion 0:  Index([ 49,  32, 439, 875, 294, 216, 799, 110, 339, 626,\n",
      "       ...\n",
      "       372, 511,  12, 774, 892, 410,  39, 550, 309, 721],\n",
      "      dtype='int64', length=275)\n"
     ]
    }
   ],
   "source": [
    "estrategiaVS=EstrategiaParticionado.ValidacionSimple(10, 0.3)\n",
    "estrategiaVS.creaParticiones(dataset_1.datos)       # datos se refiere a la matriz numérica calculada en Datos\n",
    "print(\"VALIDACIÓN SIMPLE TIC-TAC-TOE\")\n",
    "print(\"Train-particion 0: \", estrategiaVS.particiones[0].indicesTrain)       # particiones contiene la lista de particiones\n",
    "print(\"Test-particion 0: \", estrategiaVS.particiones[0].indicesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b0760ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validación simple de datos TIC-TAC-TOE\n",
      "Numero de particiones realizadas: 10\n",
      "Numero de particiones realizadas: 10\n",
      "Indice de errores por partición:\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |       0.291667 |\n",
      "+----------------+----------------+\n",
      "|              2 |       0.286458 |\n",
      "+----------------+----------------+\n",
      "|              3 |       0.270833 |\n",
      "+----------------+----------------+\n",
      "|              4 |       0.286458 |\n",
      "+----------------+----------------+\n",
      "|              5 |       0.333333 |\n",
      "+----------------+----------------+\n",
      "|              6 |       0.260417 |\n",
      "+----------------+----------------+\n",
      "|              7 |       0.28125  |\n",
      "+----------------+----------------+\n",
      "|              8 |       0.25     |\n",
      "+----------------+----------------+\n",
      "|              9 |       0.348958 |\n",
      "+----------------+----------------+\n",
      "|             10 |       0.28125  |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.02892852932708088, media: 0.2890625\n",
      "##################################################\n",
      "Indice de errores por partición (con corrección La Place):\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |       0.291667 |\n",
      "+----------------+----------------+\n",
      "|              2 |       0.286458 |\n",
      "+----------------+----------------+\n",
      "|              3 |       0.270833 |\n",
      "+----------------+----------------+\n",
      "|              4 |       0.286458 |\n",
      "+----------------+----------------+\n",
      "|              5 |       0.333333 |\n",
      "+----------------+----------------+\n",
      "|              6 |       0.260417 |\n",
      "+----------------+----------------+\n",
      "|              7 |       0.28125  |\n",
      "+----------------+----------------+\n",
      "|              8 |       0.25     |\n",
      "+----------------+----------------+\n",
      "|              9 |       0.348958 |\n",
      "+----------------+----------------+\n",
      "|             10 |       0.28125  |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.02892852932708088, media: 0.2890625\n"
     ]
    }
   ],
   "source": [
    "print(\"Validación simple de datos TIC-TAC-TOE\")\n",
    "\n",
    "estrategia = EstrategiaParticionado.ValidacionSimple(10, 0.2)\n",
    "clasificador = Clasificador.Clasificador()\n",
    "nb1 = Clasificador.ClasificadorNaiveBayes()\n",
    "errores1 = clasificador.validacion(estrategia, dataset_2, nb1, None)\n",
    "nb2 = Clasificador.ClasificadorNaiveBayes(True)\n",
    "errores2 = clasificador.validacion(estrategia, dataset_2, nb2, None)\n",
    "\n",
    "desviacion_estandar = np.std(errores1)\n",
    "media = sum(errores1) / len(errores1)\n",
    "print(\"Indice de errores por partición:\")\n",
    "table = tabulate(enumerate(errores1, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))\n",
    "print(50*\"#\")\n",
    "\n",
    "desviacion_estandar = np.std(errores2)\n",
    "media = sum(errores2) / len(errores2)\n",
    "print(\"Indice de errores por partición (con corrección La Place):\")\n",
    "table = tabulate(enumerate(errores2, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45c639b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validación cruzada de datos TIC-TAC-TOE\n",
      "Numero de particiones realizadas: 10\n",
      "Numero de particiones realizadas: 10\n",
      "SE EJECUTA LA PLACE!!!\n",
      "[[0.         0.22683706]\n",
      " [0.51476793 0.30191693]\n",
      " [0.48523207 0.47124601]] \n",
      "\n",
      "[[1.         1.22683706]\n",
      " [1.51476793 1.30191693]\n",
      " [1.48523207 1.47124601]] \n",
      "\n",
      "Indice de errores por partición:\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |       0.631579 |\n",
      "+----------------+----------------+\n",
      "|              2 |       0.178947 |\n",
      "+----------------+----------------+\n",
      "|              3 |       0.263158 |\n",
      "+----------------+----------------+\n",
      "|              4 |       0.589474 |\n",
      "+----------------+----------------+\n",
      "|              5 |       0.410526 |\n",
      "+----------------+----------------+\n",
      "|              6 |       0.4      |\n",
      "+----------------+----------------+\n",
      "|              7 |       0.505263 |\n",
      "+----------------+----------------+\n",
      "|              8 |       0.863158 |\n",
      "+----------------+----------------+\n",
      "|              9 |       0.831579 |\n",
      "+----------------+----------------+\n",
      "|             10 |       0.884211 |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.23682105169582326, media: 0.5557894736842106\n",
      "##################################################\n",
      "Indice de errores por partición (con corrección La Place):\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |       0.631579 |\n",
      "+----------------+----------------+\n",
      "|              2 |       0.178947 |\n",
      "+----------------+----------------+\n",
      "|              3 |       0.263158 |\n",
      "+----------------+----------------+\n",
      "|              4 |       0.589474 |\n",
      "+----------------+----------------+\n",
      "|              5 |       0.410526 |\n",
      "+----------------+----------------+\n",
      "|              6 |       0.4      |\n",
      "+----------------+----------------+\n",
      "|              7 |       0.505263 |\n",
      "+----------------+----------------+\n",
      "|              8 |       0.863158 |\n",
      "+----------------+----------------+\n",
      "|              9 |       0.831579 |\n",
      "+----------------+----------------+\n",
      "|             10 |       0.768421 |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.22290203803365455, media: 0.5442105263157895\n"
     ]
    }
   ],
   "source": [
    "print(\"Validación cruzada de datos TIC-TAC-TOE\")\n",
    "\n",
    "estrategia = EstrategiaParticionado.ValidacionCruzada(10)\n",
    "clasificador = Clasificador.Clasificador()\n",
    "nb1 = Clasificador.ClasificadorNaiveBayes()\n",
    "errores1 = clasificador.validacion(estrategia, dataset_2, nb1, None)\n",
    "nb2 = Clasificador.ClasificadorNaiveBayes(True)\n",
    "errores2 = clasificador.validacion(estrategia, dataset_2, nb2, None)\n",
    "\n",
    "desviacion_estandar = np.std(errores1)\n",
    "media = sum(errores1) / len(errores1)\n",
    "print(\"Indice de errores por partición:\")\n",
    "table = tabulate(enumerate(errores1, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))\n",
    "print(50*\"#\")\n",
    "\n",
    "desviacion_estandar = np.std(errores2)\n",
    "media = sum(errores2) / len(errores2)\n",
    "print(\"Indice de errores por partición (con corrección La Place):\")\n",
    "table = tabulate(enumerate(errores2, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a36b354",
   "metadata": {},
   "source": [
    "### Breve análisis de los resultados anteriores. Discutir el efecto Laplace\n",
    "Como se puede observar en ambos datasets, la validación simple suele presentar indices de fallos significativamente menores que la validación cruzada en ambos sets de datos, y para el dataset tik-tak-toe, cuando se presenta un dato con valor 0, esta corrección ayuda a rebajar el indice de fallo sutilmente en la posterior validación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf1944",
   "metadata": {},
   "source": [
    "# Apartado II (Naive-Bayes Scikit-Learn con TIC-TAC-TOE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75fdc900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def preprocess(dataset: Datos):\\n    data_wo_lastColumn = dataset.datos.iloc[:,:-1]\\n    data_lastColumn = dataset.datos.iloc[:,-1]\\n\\n    print(data_lastColumn)\\n\\n    encoder = OneHotEncoder(sparse=False, categories='auto')\\n    dwlc_encoded = np.array(encoder.fit(data_wo_lastColumn))\\n    aux = np.hstack((dwlc_encoded, data_lastColumn[np.newaxis, :]))\\n    dataset.datos = np.zeros(aux.shape)\\n    dataset.datos = aux\\n    return dataset\\n\\n# Nuevo dataset de tic-tac-toe\\nnew_dataset_2 = preprocess(dataset_2)\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Intento de OneHotEncoder que no salio bien :(\n",
    "\"\"\"def preprocess(dataset: Datos):\n",
    "    data_wo_lastColumn = dataset.datos.iloc[:,:-1]\n",
    "    data_lastColumn = dataset.datos.iloc[:,-1]\n",
    "\n",
    "    print(data_lastColumn)\n",
    "\n",
    "    encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "    dwlc_encoded = np.array(encoder.fit(data_wo_lastColumn))\n",
    "    aux = np.hstack((dwlc_encoded, data_lastColumn[np.newaxis, :]))\n",
    "    dataset.datos = np.zeros(aux.shape)\n",
    "    dataset.datos = aux\n",
    "    return dataset\n",
    "\n",
    "# Nuevo dataset de tic-tac-toe\n",
    "new_dataset_2 = preprocess(dataset_2)\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68ac3e",
   "metadata": {},
   "source": [
    "### Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15f1afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de particiones realizadas: 5\n",
      "Numero de particiones realizadas: 5\n",
      "Indice de errores por partición:\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |       0.649215 |\n",
      "+----------------+----------------+\n",
      "|              2 |       0.162304 |\n",
      "+----------------+----------------+\n",
      "|              3 |       0.439791 |\n",
      "+----------------+----------------+\n",
      "|              4 |       0.732984 |\n",
      "+----------------+----------------+\n",
      "|              5 |       1        |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.281887461770807, media: 0.5968586387434555\n",
      "##################################################\n",
      "Indice de errores por partición (con corrección La Place):\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |       0.649215 |\n",
      "+----------------+----------------+\n",
      "|              2 |       0.162304 |\n",
      "+----------------+----------------+\n",
      "|              3 |       0.439791 |\n",
      "+----------------+----------------+\n",
      "|              4 |       0.732984 |\n",
      "+----------------+----------------+\n",
      "|              5 |       1        |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.281887461770807, media: 0.5968586387434555\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "estrategia = EstrategiaParticionado.ValidacionCruzada(5)\n",
    "clasificador_nbsk_lp = Clasificador.ClasificadorNaiveBayesSKLearn(1)\n",
    "clasificador_nbsk_nlp = Clasificador.ClasificadorNaiveBayesSKLearn(1,LaPlace= False)\n",
    "\n",
    "errores1 = clasificador.validacion(estrategia, dataset_2, clasificador_nbsk_lp)\n",
    "errores2 = clasificador.validacion(estrategia, dataset_2, clasificador_nbsk_nlp)\n",
    "\n",
    "desviacion_estandar = np.std(errores1)\n",
    "media = sum(errores1) / len(errores1)\n",
    "print(\"Indice de errores por partición:\")\n",
    "table = tabulate(enumerate(errores1, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))\n",
    "print(50*\"#\")\n",
    "\n",
    "desviacion_estandar = np.std(errores2)\n",
    "media = sum(errores2) / len(errores2)\n",
    "print(\"Indice de errores por partición (con corrección La Place):\")\n",
    "table = tabulate(enumerate(errores2, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2597c3c4",
   "metadata": {},
   "source": [
    "### Gausiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfb91954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de particiones realizadas: 5\n",
      "Numero de particiones realizadas: 5\n",
      "Indice de errores por partición:\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |       0.717277 |\n",
      "+----------------+----------------+\n",
      "|              2 |       0.314136 |\n",
      "+----------------+----------------+\n",
      "|              3 |       0.596859 |\n",
      "+----------------+----------------+\n",
      "|              4 |       0.848168 |\n",
      "+----------------+----------------+\n",
      "|              5 |       0.984293 |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.2290394906834536, media: 0.6921465968586388\n",
      "##################################################\n",
      "Indice de errores por partición (con corrección La Place):\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |       0.717277 |\n",
      "+----------------+----------------+\n",
      "|              2 |       0.314136 |\n",
      "+----------------+----------------+\n",
      "|              3 |       0.596859 |\n",
      "+----------------+----------------+\n",
      "|              4 |       0.848168 |\n",
      "+----------------+----------------+\n",
      "|              5 |       0.984293 |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.2290394906834536, media: 0.6921465968586388\n"
     ]
    }
   ],
   "source": [
    "clasificador_nbsk_lp = Clasificador.ClasificadorNaiveBayesSKLearn(2)\n",
    "clasificador_nbsk_nlp = Clasificador.ClasificadorNaiveBayesSKLearn(2,LaPlace= False)\n",
    "\n",
    "errores1 = clasificador.validacion(estrategia, dataset_2, clasificador_nbsk_lp)\n",
    "errores2 = clasificador.validacion(estrategia, dataset_2, clasificador_nbsk_nlp)\n",
    "\n",
    "desviacion_estandar = np.std(errores1)\n",
    "media = sum(errores1) / len(errores1)\n",
    "print(\"Indice de errores por partición:\")\n",
    "table = tabulate(enumerate(errores1, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))\n",
    "print(50*\"#\")\n",
    "\n",
    "desviacion_estandar = np.std(errores2)\n",
    "media = sum(errores2) / len(errores2)\n",
    "print(\"Indice de errores por partición (con corrección La Place):\")\n",
    "table = tabulate(enumerate(errores2, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2a1daa",
   "metadata": {},
   "source": [
    "### Categorica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed677d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de particiones realizadas: 5\n",
      "Numero de particiones realizadas: 5\n",
      "Indice de errores por partición:\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |       0.612565 |\n",
      "+----------------+----------------+\n",
      "|              2 |       0.361257 |\n",
      "+----------------+----------------+\n",
      "|              3 |       0.434555 |\n",
      "+----------------+----------------+\n",
      "|              4 |       0.722513 |\n",
      "+----------------+----------------+\n",
      "|              5 |       0.968586 |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.21606233091566796, media: 0.6198952879581151\n",
      "##################################################\n",
      "Indice de errores por partición (con corrección La Place):\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |       0.612565 |\n",
      "+----------------+----------------+\n",
      "|              2 |       0.361257 |\n",
      "+----------------+----------------+\n",
      "|              3 |       0.434555 |\n",
      "+----------------+----------------+\n",
      "|              4 |       0.727749 |\n",
      "+----------------+----------------+\n",
      "|              5 |       0.968586 |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.21656921081960231, media: 0.6209424083769634\n"
     ]
    }
   ],
   "source": [
    "clasificador_nbsk_lp = Clasificador.ClasificadorNaiveBayesSKLearn(3)\n",
    "clasificador_nbsk_nlp = Clasificador.ClasificadorNaiveBayesSKLearn(3,LaPlace= False)\n",
    "\n",
    "errores1 = clasificador.validacion(estrategia, dataset_2, clasificador_nbsk_lp)\n",
    "errores2 = clasificador.validacion(estrategia, dataset_2, clasificador_nbsk_nlp)\n",
    "\n",
    "desviacion_estandar = np.std(errores1)\n",
    "media = sum(errores1) / len(errores1)\n",
    "print(\"Indice de errores por partición:\")\n",
    "table = tabulate(enumerate(errores1, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))\n",
    "print(50*\"#\")\n",
    "\n",
    "desviacion_estandar = np.std(errores2)\n",
    "media = sum(errores2) / len(errores2)\n",
    "print(\"Indice de errores por partición (con corrección La Place):\")\n",
    "table = tabulate(enumerate(errores2, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d79e71",
   "metadata": {},
   "source": [
    "## Analizar las diferencias de los resultados obtenidos en función del método empleado: MultinomialNB, GaussianNB y CategoricalNB. ¿Cuál ha funcionado mejor para tic-tac-toe? ¿A qué puede deberse?\n",
    "\n",
    "La mejor clasificacion es la de Multinomial, esto se debe a que debido a la naturaleza de los datos, es mejor elegir entre categorico o multinomial, pero debido a las combinaciones de x y o, es mejor la multinomial en este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86c7922",
   "metadata": {},
   "source": [
    "# Apartado II (Naive-Bayes Scikit-Learn con HEART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c6d6da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de particiones realizadas: 5\n",
      "Numero de particiones realizadas: 5\n",
      "Indice de errores por partición:\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |       0.131148 |\n",
      "+----------------+----------------+\n",
      "|              2 |       0.10929  |\n",
      "+----------------+----------------+\n",
      "|              3 |       0.114754 |\n",
      "+----------------+----------------+\n",
      "|              4 |       0.191257 |\n",
      "+----------------+----------------+\n",
      "|              5 |       0.196721 |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.037764267853925663, media: 0.14863387978142079\n",
      "##################################################\n",
      "Indice de errores por partición (con corrección La Place):\n",
      "+----------------+----------------+\n",
      "|   Nº particion |   Indice error |\n",
      "+================+================+\n",
      "|              1 |       0.131148 |\n",
      "+----------------+----------------+\n",
      "|              2 |       0.10929  |\n",
      "+----------------+----------------+\n",
      "|              3 |       0.114754 |\n",
      "+----------------+----------------+\n",
      "|              4 |       0.191257 |\n",
      "+----------------+----------------+\n",
      "|              5 |       0.196721 |\n",
      "+----------------+----------------+\n",
      "Desviación estandar: 0.037764267853925663, media: 0.14863387978142079\n"
     ]
    }
   ],
   "source": [
    "estrategia = EstrategiaParticionado.ValidacionCruzada(5)\n",
    "clasificador_nbsk_lp = Clasificador.ClasificadorNaiveBayesSKLearn(2)\n",
    "clasificador_nbsk_nlp = Clasificador.ClasificadorNaiveBayesSKLearn(2,LaPlace= False)\n",
    "\n",
    "errores1 = clasificador.validacion(estrategia, dataset_1, clasificador_nbsk_lp)\n",
    "errores2 = clasificador.validacion(estrategia, dataset_1, clasificador_nbsk_nlp)\n",
    "\n",
    "desviacion_estandar = np.std(errores1)\n",
    "media = sum(errores1) / len(errores1)\n",
    "print(\"Indice de errores por partición:\")\n",
    "table = tabulate(enumerate(errores1, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))\n",
    "print(50*\"#\")\n",
    "\n",
    "desviacion_estandar = np.std(errores2)\n",
    "media = sum(errores2) / len(errores2)\n",
    "print(\"Indice de errores por partición (con corrección La Place):\")\n",
    "table = tabulate(enumerate(errores2, 1), headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "print(\"Desviación estandar: \" + str(desviacion_estandar) + \", media: \" + str(media))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13627467",
   "metadata": {},
   "source": [
    "### ¿Por qué crees que no utilizamos los otros dos algoritmos aquí? Si es por algún problema en los datos de entrada, ¿qué transformación/es podríamos hacer para resolver el problema?\n",
    "\n",
    "Este algoritmo es adecuado para variables numéricas. Si las variables numéricas como \"Age\", \"RestingBP\", \"Cholesterol\", \"MaxHR\" y \"Oldpeak\" son las que más influyen en la variable \"Class\". Mientras que Multinomial y Categorico con las varaibles \"Sex\", \"ChestPainType\", \"FastingBS\", \"RestingECG\", \"ExerciseAngina\" y \"ST_Slope\" no es tan efectivo para \"Class\".\n",
    "\n",
    "Sí, la transformación one-hot resolveria este problema para poder usar estos dos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe4c2f",
   "metadata": {},
   "source": [
    "# APARTADO III (CONCLUSIÓN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d440ee46",
   "metadata": {},
   "source": [
    "Nuestra implementación es mejor que la de sklearn, ya que tenemos en cuenta si una columna es gaussiana o multinomial, mientras que en sklearn aplicamos para todos los datos MultinomialNB o GaussianNB, lo cual nos cuasa una tasa de error mayor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
